\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[top=30pt,bottom=30pt,left=48pt,right=46pt]{geometry}
\usepackage[fontsize=7pt]{scrextend}

\newcommand{\img}[1]{\begin{center}
    \includegraphics[width=0.4\textwidth,height=0.3\textheight,keepaspectratio]{img/#1}
\end{center} }

\title{Database System Architecture and Implementation \\
Summary}
\author{Fabian Klopfer}
\date{February 2019}

\begin{document}

\begin{twocolumn}
\section{Disk, File, Buffer Management}
\subsection{Disk}
\subsubsection{Magnetic Disks:}
\img{magnetic_disk.png}
\begin{enumerate}
	\item[Blocks:] Data is read and written to disk one block at a time. Size is multiple of the sector size.
	\item[Sector:] A sector is a single part of a track
	\item[Track:] A track is a ring on a plater
	\item[Cylinder:] A cylinder is the set of all tracks with the same diameter
\end{enumerate}
The access time t is defined as \[ t = t_s + t_r + t_t \]
where \begin{itemize}
	\item[$t_s$] seek time (movement of disk head to desired track)
	\item[$t_r$] rotational delay (waiting time until the desired sector has rotated under the disks head)
	\item[$t_t$] transfer time (time taken to read/write the block) 
\end{itemize}
Sequential reads are much faster as one only needs to seek and to wait for the disk to rotate one time per sequential instead of on every access as in random I/O \\

\subsubsection{RAID}
\begin{enumerate}
	\item[0] Striping \\
	Best Write performance, better read performance, no reliability improvements
	\item[1] Mirroring \\
	On-line backup, no performance improvements
	\item[10] Mirroring + Striping \\
	reasonable performance w extra reliablility; write intensive workloads, small subsystems. RAID 0 over RAID 1: Stripe and mirror each disk
	\item[2] ECC \\
	Uses Hamming code to do error correction
	\item[3] Bit-Interleaved parity: Byte-level stripping + extra parity disk \\
	Apropriate for large continuous block requests, bad for many small requests; Parity on separate disk
	\item[4] Block-Interleaved Parity: Block level stripping + parity disk \\
	Inferior to 5; same as 3 just on block instead of byte level; parity on separate disk
	\item[5] Block-Interleaved Distributed Parity: Block level stripping + distributed parity \\
	Good general purpose solution, best performance with redundancy for small and large r and large w ops
	\item[6] P+Q Parity: Block level stripping + double distributed parity \\
	highest level of reliability, like 5 with 2 parities
\end{enumerate}
\img{raid_overview.png}
\paragraph{Parity Scheme}: \\
Initialization: let $i(n)$ be the number of bits set to 1 at position n on disk; n-th parity bit is set to 1 if $i(n)$ is odd else 0 \\
Recovery: Let $j(n)$ be the no. of bits set to 1 at pos n on the non-failed disks. if $j(n)$ odd and parity bit 1 or $j(n)$ even and parity bit is 0, n-th value on failed disk is 0, else 1

\subsection{BufferManager}
\img{replacement_names.png}
\img{replacement_matrix.png}
\img{replacement_graphic.png}

\section{B+Tree and Hash Indexes}
Variants: 1 resembles the sorted file on attribute A, thus only one such index should exist to avoid redundant storage of records. 2 and 3 use rids where 3 groups records that match a search key k.
\begin{enumerate}
	\item $<$k, $< \dots,A=k,\dots>>$
	\item $<$k, rid$>$
	\item $<$k, [rid$_1$, ...]$>$
\end{enumerate}

\subsection{B+Tree}
\paragraph{Invariants}
\begin{itemize}
	\item Order: d
	\item Occupancy: $d-1 < |\text{values}| < 2d+1$. Exception: root
	\item Fan-out: Non-leaf holding m keys has m+1 children
	\item Sorted Order nodes contain elements in comparator order, all children to the left are smaler wrt. comparator than the value in the parent and the subtrees to the right.
	\item Balanced: All leaf nodes are on the same level
	\item Height: $\log_d N$
\end{itemize}

\subsection{Hash-based Indexes}
%TODO put growth/shrinkage in here; 
%TODO add samples
%TODO add proper algo
"Unbeatable for Equality operations", no support for range queries
\img{hash_fn.png}
\img{hash_family.png}

 \subsubsection{Extendible Hashing}
Uses in-memory bucket directory to keep track of the actual primary buckets by adapting the hash function and the access to the buckets

\img{extendible_hashing.png}

\paragraph{Searching:} buckets is an array of size $2^{n-1}$ where each entry points to a corresponding bucket
\begin{enumerate}
	\item n = global depth
	\item b = $h(k) \& (2n-1)$ // mask last n-1 bits
	\item bucket = buckets[b]
\end{enumerate}

\paragraph{Insert:} If there is free space in the corresponding bucket just insert, else 
\begin{enumerate}
	\item Split the bucket by creating a new bucket and use bit position $d+1$ to redistribute the entries where $d$ is the local depth
	\item if $d+1 > n$, $n++$ and double the directory size. The hashing uses now d+1 bits
	\item let the old bucket be pointed to by 0[...] and the new be pointed to by 1[...]
	\item if no value goes to the new bucket an overflow chain is initialized
\end{enumerate}

\paragraph{Delete:} Just delete. If bucket is empty merge with level -1 bucket. If all local directories use n-1 bits, $n--$

\subsubsection{Linear Hashing}
\img{linear_hashing.png}
\begin{enumerate}
	\item Init: level = 0, next = 0
	\item current hash fn = $h_{\text{level}}$, active hash buckets: $[0,\dots, 2^{\text{level}} \cdot N]$
	\item whenever a certain criterion is met, split the bucket which the next pointer references (e.g. \% occupancy reached in a bucket, overflow chain grew longer than x, $\dots$
	\item Level is increased, if next is extended further than $2^{\text{level}} \cdot N -1 $
\end{enumerate}

\paragraph{Split}: All buckets with position < next have been already rehashed \\
\begin{enumerate}
	\item Allocate new bucket and append it at position $2^{\text{level}} \cdot N + \text{next}$
	\item Redistribute entries in the bucket that next references by rehashing with $h_{\text{level}+1}$
	\item next++, if next $> 2^{\text{level}} \cdot N - 1$, next = 0; level++
\end{enumerate}

\paragraph{Insert:} like in static hashing plus additional check for split criterion \\

\paragraph{Delete:} like with static hashing plus merging bucket at next and $\text{next} + 2^{\text{level}} N$ when the bucket on the next higher level is empty
\\ if bucket[$2^{\text{level}} \cdot N + next$].empty:
\begin{enumerate}
	\item remove page pointed to by bucket[$2^{\text{level}} \cdot N + next$] from hash table 
	\item next--, if next < 0, level--, next = $2^{\text{level}} \cdot N + next$
\end{enumerate}





\section{Query Evaluation}

\subsection{Two-Way Merge Sort}
\img{2_way_merge_sort.png}

\paragraph{Costs:} Each pass needs to read N pages, sort them in-memory and write them out again $\Rightarrow 2N$ I/O ops per pass \\
in total there are pass 0 and k subsequent pass $\Rightarrow 1 + log_2 {N}$
In Total Two-way Merge Sort costs \[ 2 N (1+ log_2 {N}) \ \text{I/O ops}\]

\subsection{External Merge Sort}
like 2-way merge sort, but reduces the number of runs by using more buffer space to avoid creating one page runs in pass 0 and reduces the number of passes by merging more than two runs at a time.
\img{external_ms.png}

\paragraph{Costs:} As in two way: read, sort, write $\Rightarrow 2N$ \\
In pass 0 only $\lceil \frac{n}{B}\rceil$ are written thus only needs $\lceil \log_{B-1} \lceil \frac{n}{B}\rceil\rceil$ where B-1 pages are merged at the same time
In Total External Merge Sort costs \[ 2 N (1+ \lceil \log_{B-1} \lceil \frac{N}{B}\rceil\rceil) \ \text{I/O ops}\]

\paragraph{B+ Tree for Sorting}
Clustered B+Tree Index: just load the N pages as they are already sorted. \\
If unclustered, worst case is $|R| \cdot ||R||$

\subsection{Join}
Most basic variant is to calculate the cross product between the relations and apply selection according to the join predicate.

\subsubsection{Nested Loops Join}
Needs 3 buffer pages \\
\img{nlj_algo}
\img{nlj_costs}


\subsubsection{Block Nested Loops Join}
 Reads both relations in blocks of $b_1, b_2$ pages respectively
\img{bnlj_basic}
Block Nested Loops Join Costs: $\lceil ||R_1||/b_1 \rceil \cdot \lceil ||R_2||/b_2 \rceil$
\img{bnlj_hash_g}
\img{bnlj_hash}

\paragraph{I/O Costs:} \[ \lceil ||S|| / B-2 \rceil + \lceil ||S|| / B-2 \rceil \cdot ||R||  \]

\subsubsection{Index Nested Loops Join}
particularly usefull when index is clustered and join is very selective \\
\img{inl_algo}
\img{inl_cost}

\paragraph{Costs of an Index access}: \\
\begin{itemize}
	\item Hash Index: $1.2 \begin{cases} 
	1.2 & clustered \\
	n & unclustered \\
	\end{cases}$
	\item B+Tree:  $log(|R_2|) \begin{cases} 
	1 & clustered \\
	n & unclustered \\
	\end{cases}$
\end{itemize}

\subsubsection{Sort Merge Join}

\img{smj_algo}
\img{smj_costs}


\subsubsection{Grace Hash Join}
Works only for equality predicates. Two Phases following divide and conquer: Partitioning phase and do per partition in-memroy joins (Probing phase). Needs $B > \sqrt{f \cdot ||R||}$ Buffer pages where $f$ is the factor of increase to maintain a hash table over the partition instead of the partition only, so that partition stays in memory
\img{ghj_part}
\img{ghj_probe}
\img{ghj_algo}
\img{ghj_costs}

\subsection{Bypass selection} 
\begin{enumerate}
	\item Convert selection condition to CNF
	\item apply most selective/cheapest predicate first and safe disjunct tuples (true/false on predicate $p_1$) 
	\item repeat step 2 until all conjuncts are applied (when a conjunct contains disjuncts, just chain them)
\end{enumerate}
\img{selection_bypass}


\subsection{Projection}
\img{projection_sort}
\img{projection_sort_elim}
\img{projection_hash_p0}
\img{projection_hash_p1}


\section{Query Optimization}
\begin{enumerate}
	\item Query Parser: Parse Q and derive a relational algebra expression E
	\item \textbf{Rewrite optimization (logical level):} From E generate set of logical plans L transforming and simplifying E
	\item \textbf{Cost-based Optimization (physical level):} Generate a set of physical plans P by annotating the plans in L with access paths and operator algorithms
	\item \textbf{Plan cost estimator:} Estimate the costs of each plan and chose the best one
	\item Query Plan Evaluator: Execute the plan and return the result to the UI
\end{enumerate}
\textbf{Search space} $\equiv$ logical level $\cup$ physical level

\subsection{Relational Algebra Rewriting}
\begin{enumerate}
	\item Break apart conjunctive selections (Rule 1)
	\item Move selections down the query tree (Rules 2, 9, 15)
	\item Replace selection-cross product pairs with joins (Rule 8)
	\item Break list of projections apart \& move them down, create new projections where possible (Rules 3, 10, 14)
	\item Perform joins with the smallest expected result first
\end{enumerate}
\begin{enumerate}
	\item \textbf{Cascading selections}
	\[ \sigma_{c_1 \wedge \dots \wedge c_n}(R) \equiv \sigma_{c_1}(\dots \sigma_{c_n}(R) \dots) \]
	
	\item \textbf{commutativity of selections}
	\[ \sigma_{c_q }( \sigma_{c_p}(R) ) \equiv \sigma_{c_p}( \sigma_{c_q}(R) ) \]
	
	\item \textbf{Cascading Projections}
	\[ \pi_{c_1 \wedge \dots \wedge c_n}(R) \equiv \pi_{c_1}(\dots \pi_{c_n}(R) \dots) \]
	
	\item \textbf{Folding selections:} with $a_i \subseteq a_{i+1}$ only the last projection is needed (cutting off step by step vs. doing all cutoffs once)
	\[ \sigma_{a_1}(R) \equiv \sigma_{a_1}(\dots \sigma_{a_n}(R) \dots) \]
	
	\item \textbf{Cross-Product and all Joins are associative} with r involves only T and S, p only involves R and S
	\[ (R \bowtie_p S) \bowtie_{q \wedge r} T \equiv R \bowtie_{p \wedge q} (S \bowtie_r T) \]
	
	\item \textbf{Cross-Product and Natural Join are commutative}
	\[ R \times S \equiv S \times R \]
	\[ R \bowtie S \equiv S \bowtie R \]
	
	\item \textbf{Selection and cross product form a join}
	\[ \sigma_p(R \times S) \equiv R \bowtie_p S \] 
	
	\item \textbf{Selections and joins can be combined}
	\[ \sigma_q(R \bowtie_p S) \equiv R \bowtie_{p \wedge q} S \] 
	
	\item \textbf{Selections commutes with Joins and cross-product} let q only involves R
	\[ \sigma_q(R \bowtie_p S) \equiv \sigma_q(R) \bowtie_{p} S \]     
	
	\item \textbf{Selections and projections distribute over joins and cross products} let p only involve R, q only involve S
	\[ \sigma_{p \wedge q}(R \bowtie_r S) \equiv \sigma_p(R) \bowtie_{r} \sigma_q(S) \] 
	\[ \pi_{a}(R \bowtie_r S) \equiv \pi_{a_1}(R) \bowtie_{r} \pi_{a_2}(S) \] 
	
	\item \textbf{Selections and Projections commute } if the projections keeps all attributes involved in the selection predicates
	\[ \pi_a(\sigma_p(R)) \equiv \sigma_p(\pi_a(R)) \] 
	
	\item \textbf{commutativity of Union and Intersection}
	\[ R \cup S \equiv S \cup R  \]
	\[ R \cap S \equiv S \cap R  \]
	
	\item \textbf{Union and Intersection are associative}
	\[ (R \cup S) \cup T \equiv R \cup (S \cup T) \]
	\[ (R \cap S) \cap T \equiv R \cap (S \cap T) \]
	
	\item \textbf{Projection distributes over Union}
	\[ \pi_{a}(R \cup S) \equiv \pi_{a}(R) \cup \pi_{a}(S) \] 
	
	\item \textbf{Selection, Union, Intersection and Difference are distributive}
	\[ \sigma_{p}(R \cup S) \equiv \sigma_{p}(R) \cup \sigma_{p}(S) \] 
	\[ \sigma_{p}(R \cap S) \equiv \sigma_{p}(R) \cap \sigma_{p}(S) \] 
	\[ \sigma_{p}(R \setminus S) \equiv \sigma_{p}(R) \setminus \sigma_{p}(S) \] 
	
	\item \textbf{Selection, Intersection and Difference are commutative}
	\[ \sigma_{p}(R \cap S) \equiv \sigma_p(R) \cap S \] 
	\[ \sigma_{p}(R \setminus S) \equiv \sigma_p(R) \setminus S \] 
\end{enumerate}


\subsection{Plan Enumeration}
\begin{itemize}
	\item Plans without Index
	\begin{enumerate}
		\item heap file scan
		\item selection \& join on-the-fly
		\item sort according to group by
		\item apply aggregation and having clauses on-the-fly
	\end{enumerate}
	\item Single-Index Access Path
	\begin{enumerate}
		\item Choose index that retrieves fewest pages
		\item apply projections and non-primary selections
		\item compute group by and aggregation by sorting
	\end{enumerate}
	\item Multiple-Index Access Path
	\begin{enumerate}
		\item Retrieve and intersect rid sets and sort result by page id
		\item retrieve tuples that satisfy primary condition of all indexes
		\item apply projections and non-primary selection terms. followed by grouping and aggregation
	\end{enumerate}
	\item Sorted Index Access Path
	\begin{enumerate}
		\item Retreive tuples in order required by group by
		\item apply selection and projection to each retreived tuple on the fly
		\item compute aggregate
	\end{enumerate}
	\item Index-Only Access Path
	\begin{enumerate}
		\item Do index scan
		\item apply selection and projection on the fly
		\item sort to group and do aggregation
	\end{enumerate}
\end{itemize}


\subsection{Dynamic Programming}
\paragraph{Principle of Optimality:} The Assumption is that in order to find an optimal global plan, it is sufficient to consider optimal plans for all possible sub-plans \\
\img{dynamic_prog}
\img{dynamic_prog_algo}
\img{greedy_join_enum}

\subsection{Histograms}
\img{cardinality_hist_width}
\img{cardinality_hist_depth}

\subsection{Nested Subqueries}
\img{nested_sub_types}
\img{nested_sub_nj}
\img{nested_sub_ja}
\img{nested_sub_ja_0}
\img{nested_sub_ja_1}
\img{nested_sub_ja2}

\img{nested_sub_ex}
\img{nested_sub_any}
\img{nested_sub_algo}

\end{twocolumn}


\end{document}
